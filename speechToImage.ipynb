{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0880c1",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware settings\n",
    "device = \"cpu\" # cpu, cuda, mps\n",
    "\n",
    "# whisper settings\n",
    "model_size = \"large\" # tiny, base, small, medium, large\n",
    "\n",
    "# local stable-diffusion settings\n",
    "num_inference_steps = 51 # default: 51\n",
    "\n",
    "# Output settings\n",
    "out_path = \"./gallery/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a0466",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "from IPython.display import Audio\n",
    "\n",
    "import whisper\n",
    "model = whisper.load_model(model_size, device=device)\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "!mkdir -p {out_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49bb72",
   "metadata": {},
   "source": [
    "### Get audio from microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39397c86-5a17-4d94-b82a-83176cfb36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ee13a",
   "metadata": {},
   "source": [
    "### Detect, transcribe and translate audio using OpenAI's `whisper` speech-to-text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23fe300-f9af-4109-aec6-46da8e497168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save audio to temporary file\n",
    "rec_file_name = \"tmp.webm\" # must use .webm\n",
    "recorder.save(rec_file_name)\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(rec_file_name)\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# remove the temporary audio file\n",
    "!rm {rec_file_name}\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "lang = max(probs, key=probs.get)\n",
    "\n",
    "# print detected language\n",
    "try:\n",
    "    print(babel.Locale(lang).get_language_name())\n",
    "\n",
    "# whisper uses a deprecated language code for Hebrew, see github.com/openai/whisper PR #401\n",
    "except babel.UnknownLocaleError:\n",
    "    if lang == \"iw\":\n",
    "        lang = \"he\"\n",
    "    else:\n",
    "        raise babel.UnknownLocaleError(f\"unknown locale {lang}\")\n",
    "\n",
    "# transcribe the spoken audio (corrective feedback for user who does not speak English)\n",
    "options = whisper.DecodingOptions(fp16 = False, task=\"transcribe\")\n",
    "result = whisper.decode(model, mel, options)\n",
    "result_orig = result\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)\n",
    "\n",
    "if lang != \"en\":\n",
    "    # translate the spoken audio (for use with text-to-image)\n",
    "    options = whisper.DecodingOptions(fp16 = False, task=\"translate\")\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    # print the translated text\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaeab8",
   "metadata": {},
   "source": [
    "### Generate images using Stability AI's `stable-diffusion`, locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cpu\":\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\"../stable-diffusion-v1-5\")\n",
    "else:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\"../stable-diffusion-v1-5\", \n",
    "                                                   torch_dtype=torch.float16, \n",
    "                                                   revision=\"fp16\")\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = result.text\n",
    "\n",
    "# First-time \"warmup\" pass\n",
    "_ = pipe(prompt, num_inference_steps=1)\n",
    "\n",
    "# Result generation\n",
    "im = pipe(prompt, num_inference_steps=num_inference_steps).images[0]\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e8835",
   "metadata": {},
   "source": [
    "### Generate images using Stability AI's `stable-diffusion`, using DeepAI's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "r = requests.post(\n",
    "    \"https://api.deepai.org/api/stable-diffusion\",\n",
    "    data={\n",
    "        #'text': result.text,\n",
    "        'text' : \"Astonauts eating thai food in space\"\n",
    "    },\n",
    "    headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
    ")\n",
    "im = Image.open(urllib.request.urlopen(r.json()['output_url']))\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749c698",
   "metadata": {},
   "source": [
    "### Save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714859e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.save(out_path + result_orig.text.replace(\" \", \"_\").replace(\".\", \"\").replace(\",\", \"\") + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22a6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
